---
title: "Regression Analysis"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

```{r setup, echo = FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
library(corrplot)
library(modelr)

set.seed(1)

knitr::opts_chunk$set(
  fig.width = 12,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```

```{r echo = FALSE, warning = FALSE, message = FALSE}
tidied = 
  read.csv("./data/cleaned.csv") %>%
  rename(city = metropolitan_status,
         noc = number_of_children,
         college = college_attendance_status,
         income = anually_family_income) %>%
  mutate(city = as.factor(city),
         college = as.numeric(recode(college, "Yes" = "1", "No" = "0")),
         race = as.factor(race),
         noc = as.factor(noc),
         city = recode(city, "in metropolitian but mixed of central city" = "metro mixed central", "in metropolitan and central city" = "metro & central", "in metropolitan but not in central city" = "metro not central", "mixed of metropolitian status" = "mixed metro", "Not in metropolitan area" = "non-metro","in metropolitian but not in central city" = "metro not central"),
         race = recode(race, "American Indian or Alaska Native" = "AmeInd/AK", "Other Asian or Pacific Islander" = "Asian/Pacific", "in metropolitian but not in central city" = "metro not central")) %>%
  drop_na(income)

all = 
  tidied %>%
  mutate(race = fct_infreq(race),
         city = fct_infreq(city),
         noc = fct_inseq(noc)) %>%
  group_by(year, age, city, race, noc, states) %>%
  mutate(count = "1",
         count = as.numeric(count),
         income = income/10000,
         percent = 100*sum(college)/sum(count)) %>%
  ungroup()
```

## Data Description


### Composition

#### Race 

```{r echo = FALSE, warning = FALSE, message = FALSE}
all %>%
  group_by(year, race) %>%
  summarise(race_count = sum(count)) %>%
  ggplot(aes(x = year, y = race_count, fill = race)) +
  geom_bar(alpha = 0.5, stat = "identity") +
  labs(x = "Year",
       y = "Race count",
       title = "Race Distribution") +
  scale_x_continuous(breaks = seq(2008, 2018, 1),labels = c(2008:2018)) 
        
```


#### Geography

```{r echo = FALSE, warning = FALSE, message = FALSE}
all %>%
  group_by(year, city) %>%
  summarise(city_count = sum(count)) %>%
  ggplot(aes(x = year, y = city_count, fill = city)) +
  geom_bar(alpha = 0.5, stat = "identity") +
  labs(x = "Year",
       y = "City count",
       title = "City Distribution") +
  scale_x_continuous(breaks = seq(2008, 2018, 1),
                   labels = c(2008:2018)) 
     
```


#### Number of Children

```{r echo = FALSE, warning = FALSE, message = FALSE}
all %>%
  group_by(year, noc) %>%
  summarise(noc_count = sum(count)) %>%
  ggplot(aes(x = year, y = noc_count, fill = noc)) +
  geom_bar(alpha = 0.5, stat = "identity") +
  labs(x = "Year",
       y = "NOC count",
       title = "Number of Children") +
  scale_x_continuous(breaks = seq(2008, 2018, 1),
                   labels = c(2008:2018)) 
```


## Correlation Matrix

```{r echo = FALSE, warning = FALSE, message = FALSE}
corr_data = 
  cor(cbind(enrollment_rate = pull(all, percent),
        model.matrix(percent~income + race + city + noc, data = all)[,-1])
  )

corr_data %>% 
  corrplot(method = "color", addCoef.col = "black", tl.col = "black", tl.srt = 45, insig = "blank" , number.cex = 0.7, diag = FALSE)


```

**Comments:** From the correlation matrix, it could be observed that the correlation between any two subgroups of predictors is less than 0.3, indicating there is a weak or no correlation between covariates and less likely to have multicollinearity.The predictors tend to be independent of each other.  Values less than 0 indicate a negative correlation; values greater than 0 indicate a positive correlation. 


## Modeling


### Predictors

* race: Race with 7 levels: `r levels(all$race)`

* city: Metropolitan Status with 5 levels: `r levels(all$city)`

* noc: Number of Children with 9 levels: `r levels(all$noc)`

* income: Annually Family Income in 10,000 dollars, with a range of (`r min(all$income)`, `r max(all$income)`).

### Outcome

* percent (%): Enrollment rate is calculated after grouping by year, age, city, race, noc and states variables; highest_degree and school_type are not grouped since both variables are directly correlated with the enrollment/attendance rate. 


### Multiple Linear Regression 

The fitted model:

$$ \hat{percent} = \beta_0 + \beta_1income + \beta_2race + \beta_3city + \beta_4noc$$


```{r echo = FALSE, warning = FALSE, message = FALSE}
fit_linear = lm(percent~income + race + city + noc, data = all)

fit_linear %>%
  broom::tidy() %>%
  mutate(term = str_replace(term, "^race", "Race:"),
         term = str_replace(term, "^city", "City:"),
         term = str_replace(term, "^noc", "NOC:")) %>%
  knitr::kable(digits = 3)
  
```

**Comments:** The table above displays results of the multiple linear regression. As we can see from the summary, there is a significant association between annually family income and college attendance rate, however, the interesting part is there is actually a negative effect on the college attendant rate, but if we look through the overall trend plot from [here](plot.html) between income and college attendant rate, we can find that it should be a positive association, and thus we did 2 further regressions after stratifying the race in this section.

However, the association between race groups of American Indian/Alaska Natives and attendance rate is not significant, compared to the White.

In addition, for one unit increase in "city", the estimated college attendance rate will decrease to some extent, adjusting for other predictors.

For the predictor NOC, the significant association is only observed for the group of 1 or 2 children in the family.


#### Linear regression for African American 
```{r echo = FALSE, warning = FALSE, message = FALSE}
AA_df = all %>% 
  filter(race == "African American")
fit_AA = lm(percent~income  + city + noc, data = AA_df)
fit_AA %>%
  broom::tidy() %>%
  mutate(term = str_replace(term, "^race", "Race:"),
         term = str_replace(term, "^city", "City:"),
         term = str_replace(term, "^noc", "NOC:")) %>%
  knitr::kable(digits = 3)
```

#### Linear regression for non African American 
```{r echo = FALSE, warning = FALSE, message = FALSE}
Other_df = all %>% 
  filter(race != "African American")
fit_other = lm(percent~income  + city + noc, data = Other_df)
fit_other %>%
  broom::tidy() %>%
  mutate(term = str_replace(term, "^race", "Race:"),
         term = str_replace(term, "^city", "City:"),
         term = str_replace(term, "^noc", "NOC:")) %>%
  knitr::kable(digits = 3)
```

**Comment:** The two regression above shown a significantly difference in the coefficient of income, and this might suggest several discrimination, detailed discussion is in the conclusion part.


### Model Diagnostics

```{r echo = FALSE, warning = FALSE, message = FALSE}
par(mfrow=c(2,2))
plot(fit_linear)
```

**Comments:** Based on the "Theoretical Quantiles" graph, the residuals are not quite normally distributed especially near both ends. The points in the middle fall on/around the line.The graph of "Residuals s Fitted" supports residuals have a mean of 0. A few outliers are observed in the "Residuals vs Leverage" plot, and one of them has influenced the accuracy of regression given the large cook's distance. Plus, residuals are biased around the horizontal line. Thus, the assumptions of linear models are not completely supported. 


### Logit Transformation

Given the results of linear regression with raw data, the following analysis is based on transformed percent values. Original values of 0 and 1 are transformed to "-Inf" and "Inf" respectively, thus cannot be included in regression analysis. 

$$ percent^* = \beta_0 + \beta_1income + \beta_2race + \beta_3city + \beta_4noc$$
Transformation: $$ percent^* = log(\frac{percent}{100-percent})$$

```{r echo = FALSE, warning = FALSE, message = FALSE}
transf = all %>%
  mutate(transf_percent = log(percent/(100-percent))) %>%
  filter(transf_percent != "-Inf",
         transf_percent != "Inf")

fit_logit = lm(transf_percent~income + race + city + noc, data = transf)
par(mfrow=c(2,2))
plot(fit_logit)
```

**Comment:** After transformation and filtration of data, the residuals are distributed approximately normal as compared to the previous distribution, even though some points near the bottom still don't fit well. The variance seems constant, and no more influential outliers are observed in this case. 


## Discussion

The outcome of interest in this study is the attendance rate which is composed of percentage values inflated with 0 and 1. According to the model diagnosis, the linear regression is not a quite good choice to analyze data, and the results of MLR could be doubtful. The logit transformation provides a better distribution of residuals, while the results are still biased because the data excludes percent of 0 and 1, which will make great influence on predicting certain subgroups' outcome, such as African Americans. A future research question similar to our topic would be if going to college is related to different characteristics, and in this case, a logistic regression could be done in a more straightforward way. 